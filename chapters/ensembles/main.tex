\documentclass[10pt,a4paper]{article}

\bibliographystyle{gost} 
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{authblk}
% Переопределение для удаления слова "and" перед последним автором
\renewcommand\Authands{, } % Удаляем слово "and"


\newcommand{\appropto}{\mathrel{\vcenter{
  \offinterlineskip\halign{\hfil$##$\cr
    \propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}

\def\app#1#2{%
  \mathrel{%
    \setbox0=\hbox{$#1\sim$}%
    \setbox2=\hbox{%
      \rlap{\hbox{$#1\propto$}}%
      \lower1.1\ht0\box0%
    }%
    \raise0.25\ht2\box2%
  }%
}
\def\approxprop{\mathpalette\app\relax}


\input{Includes/preambule}

\title{Композиции классификаторов}

\begin{document}

\section{Композиции классификаторов}
%\section*{Основные понятия,методы стохастического ансмаблирования, бэггинг}

В задачах классификации, регрессии и прогнозирования нередки ситуации,    когда ни один алгоритм не обеспечивает нужного качества исходной модели.  В таких случаях на помощь приходит метод композиции классификаторов, также известный как ансамблевые методы, который сочетает несколько моделей для улучшения точности и устойчивости предсказаний по сравнению с использованием одиночного классификатора. Идея применения метода зключается в том, что объединение различных алгоритмов, каждый из которых может иметь свои сильные и слабые стороны, позволяет компенсировать недостатки отдельных моделей и достигать лучших результатов.

\subsection{Основные понятия}

\begin{itemize}
    \item $X^{l \cdot n} = (x_1, ... , x_\textit{l})$ --- обучающая выборка; $Y^\textit{l} = (y_1, ... , y_\textit{l})$ - вектор ответов;
\item $a_t: X \to Y, \ t = 1, \dots, T$ --- обучаемые алгоритмы $a_t: X \to Y$, аппроксимирующие неизвестную целевую зависимость $y_i = y^*(x_i)$.
\end{itemize}
   \textbf{Идея ансамблирования} (И.Ю.Журавлев): как из множества по отдельности плохих алгоритмов \textit{$ a_t(x) $} сделать один хороший?\\ 
   \\ 
   \textbf{Понятие композиции базовых алгоритмов}  
   
   Любой базовый алгоритм представим в следующем виде: $ a_t(x) = C(b_t(x))$ 
   
   $a_t(x): \textit{X}  \overset{b_t}{\longrightarrow} \textit{R} \overset{C}{\longrightarrow} \textit{Y}$, где \textit{C} --- решающее правило, \textit{R} --- удобное пространство оценок, $b_t$ - алгоритмические операторы.

    Основная идея ансамблирования заключается в декомпозиции базового алгоритма: создании \textbf{ансамбля} \textit{агрегирующей операции F }, которая комбинирует результаты нескольких базовых алгоритмов для повышения точности предсказаний перед использованием решающего правила: 

\ \
    
    $F: \mathbb{R}^T \to \mathbb{R}$ – агрегирующая операция базовых алгоритмов $a_1, \dots, a_T$

    $$a(x) = C(F(b_1(x), \dots, b_T(x)))$$

    
Суперпозиции вида $F(b_1, ... , b_T )$ являются отображениями из X в $\mathbb{R}$, то есть, опять-таки, алгоритмическими операторами. Это позволяет строить иерархические композиции, применяя определение ансамбля рекурсивно.
Ранее не существовало четкого разделения алгоритма на две составляющие. Выбор функции ансамблирования позволяет  агрегировать результат нескольких моделей для повышения итоговой точности предсказаний.

\ \
\begin{itemize}
    \item \textbf{Пример 1:} Классификация, $Y$ – конечное множество.
    
    В этом случае $R = Y$, а $C(b) \equiv b$ – решающее правило не используется.
    \item \textbf{Пример 2:} Классификация на 2 класса, $Y = \{-1, +1\}$, алгоритм имеет вид:
    $$a(x) = \text{sign}(b(x)),$$
    В этом случае алгоритмические операторы называют также вещественнозначными классификаторами \textit{(real-valued classifiers)}: $R = \mathbb{R}$, $b: X \to \mathbb{R}$, $C(b) \equiv \text{sign}(b)$
\end{itemize}

\subsection{Агрегирующие функции}
Агрегирующая функция должна удовлетворять ряду требованиям для обеспечения эффективного комбинирования предсказаний отдельных моделей. Перечислим их:
\begin{itemize}
    \item $F(b_1, \dots, b_T) \in [\min_t b_t, \max_t b_t]$ – среднее по Коши $\forall x$;
    \item $F(b_1, \dots, b_T)$ монотонно не убывает по всем $b_t$;
    \item \textbf{Интерпретируемость}: позволяла понять, как и почему принимается то или иное решение;
    \item  \textbf{Согласованность}: она должна обеспечивать согласованность результатов, т.е. предсказания ансамбля должны быть устойчивыми при малых изменениях в данных или в отдельных моделях.
\end{itemize}

\subsubsection*{Примеры агрегирующих функций:}
\begin{itemize}
    \item \textbf{Простое голосование} (\textit{simple voting}):
    $$F(b_1, \dots , b_T) = \frac{1}{T} \sum_{t=1}^T b_t$$
    \item \textbf{Взвешенное голосование} (\textit{weighted voting}):
    $$F(b_1, \dots, b_T) = \sum_{t=1}^T \alpha_t b_t, \quad \sum_{t=1}^T \alpha_t = 1, \quad \alpha_t \ge 0$$
    \item \textbf{Смесь алгоритмов} (\textit{mixture of experts}) с функциями компетентности (\textit{gating function}) $g_t: X \to \mathbb{R}$
    $$F(b_1, \dots, b_T, x) = \sum_{t=1}^T g_t(x) b_t(x)$$
\end{itemize}
\subsection{Проблема разнообразия базовых алгоритмов}
Явное преимущество композиции алгоритмов - возможность использовать независимые модели при построении ансамбля. Однако на практике  часто возникает ситуация, когда используется один и тот же алгоритм для создания ансамбля. Это, в свою очередь, приводит к тому, что модели в ансамбле не являются полностью независимыми.

Тем не менее, даже в случае использования одного и того же алгоритма, можно добиться некоторого разнообразия между моделями. Это может быть сделано за счет изменения параметров алгоритма, использования различных подмножеств данных для обучения (например, с помощью бэггинга, \textit{см. далее}) или применения различных техник предобработки данных. Кроме того, можно использовать различные способы инициализации или подходы к обучению, что также может привести к созданию моделей с различной производительностью.

\subsection{Методы стохастического ансамблирования} % Stochastic Ensemble Methods
Один из подходов к достижению этого разнообразия заключается в использовании методов рандомизации. Рандомизация позволяет генерировать различные обучающие подмножества данных, выбирать случайные подмножества признаков или изменять параметры моделей, что приводит к созданию разнообразного ансамбля и повышению его обобщающей способности. В данном разделе перечислены различные методы рандомизации, используемые для повышения разнообразия базовых моделей в ансамблях.

\ \

\textbf{Способы повышения разнообразия с помощью рандомизации:} 
\begin{itemize}
    \item \textit{bagging} (\textit{bootstrap aggregating}) – подвыборки обучающей выборки с возвращением: из исходной выборки размером \textit{N} образуется \textit{m} выборок, каждая из которых имеет тот же размер, что и исходный набор данных, но создаются они путем равномерного выбора элементов из исходного набора с возвратом. В каждую выборку попадает $1 - (1 - \frac{1}{\ell})^\ell$ уникальных объектов исходной выборки
    \item \textit{pasting} – случайные обучающие подвыборки 
    \item \textit{random subspaces} – случайные подмножества признаков 
    \item \textit{random patches} – случ. подмн-ва объектов и признаков 
    \item \textit{cross-validated committees} – выборка разбивается на $k$ блоков ($k$-fold) и делается $k$ обучений без одного блока 
\end{itemize}
Пусть $\mu: (G, U) \mapsto b$ – метод обучения по подвыборке $U \subseteq X^\ell$, использующий только признаки из $G \subseteq F^n = \{f_1, \dots, f_n\}$ 

\ \ 

\textbf{Алгоритм стохастического ансамблирования:}
\\
\textbf{Вход:} 

обучающая выборка $X^\ell$; параметры: 

$T$, $\ell'$ – объём обучающих подвыборок, 

$n'$ – размерность признаковых подпространств, 

$\varepsilon_1$ – порог качества базовых алгоритмов на обучении, 

$\varepsilon_2$ – порог качества базовых алгоритмов на контроле.
\\ 
\textbf{Выход:} 

базовые алгоритмы $b_t$,  $t = 1, \dots, T$: 
\begin{itemize}
    \item $U_t$ = случайная подвыборка объёма $\ell'$ из $X^\ell$; 
    \item $G_t$ = случайное подмножество мощности $n'$ из $F^n$; 
    \item $b_t = \mu(G_t, U_t)$; % $b_t = \mu(G_t, U_t)$;
    \item \textbf{если} $Q(b_t, U_t) > \varepsilon_1$ \textbf{то} не включать $b_t$ в ансамбль; 
    \item \textbf{если} $Q(b_t, X^\ell \setminus U_t) > \varepsilon_2$ \textbf{то} не включать $b_t$ в ансамбль; 
\end{itemize}
\ \
\textbf{Применение агрегирующей функции:} 

В простейшем случае используется простое голосование:
$$b(x) = \frac{1}{T} \sum_{t=1}^T  b_t(x)$$

\subsection*{Преобразование простого голосования во взвешенное}
Мы ожидаем, что некоторые базовые алгоритмы могут быть более точными и надежными, чем другие. Поэтому перейдем от простого голосования к взвешенному, где каждому классификатору присваивается определенный вес, отражающий его вклад в итоговое предсказание, для повышения точности и гибкости ансамбля.
\begin{itemize}
    \item \textbf{Линейная модель} над готовыми признаками $b_t(x)$:
    $$b(x) = \sum_{t=1}^T \alpha_t b_t(x)$$
    \item \textbf{Обучение:} МНК для регрессии, LR для классификации: 
    $$Q(\alpha, X^\ell) = \sum_{i=1}^\ell \mathcal{L}(b(x_i), y_i) \to \min_\alpha$$
    \textbf{Регуляризация:} $\alpha_t \ge 0$ либо LASSO: $\sum_{t=1}^T |\alpha_t| \
    \lambda$. 
\end{itemize}
Другой подход при выборе весов модели, заключается в предположении, что наши модели являются \textit{независимыми}. Тогда вохможно применение байесовского классификатора:
\begin{itemize}
    \item \textbf{Наивный байесовский классификатор} предполагает независимость с.в. $b_t(x)$ и даёт аналитическое решение: 
    $$\alpha_t = \ln \frac{1 - p_t}{p_t}, \quad t = 1, \dots, T,$$
    $p_t$ – оценка вероятности ошибки базового алгоритма $b_t$.
\end{itemize}




\subsection*{Задачи}
\subsubsection*{Задача 1}
Напишите декомпозицию алгоритма задачи классификации на K классов в общем случае. Каким в этом случае будет решающее правило С?
\subsubsection*{Задача 2}
Напишите декомпозицию алгоритма задачи регрессии в общем случае. Используется ли в данном случае решающее правило?
\subsubsection*{Задача 3}
Оцените уникальность подвыборки в методе bootstrap aggregating, для избыточного набора объектов исходной выборки, т.е. при $\ell \to \infty$.

\end{document}
